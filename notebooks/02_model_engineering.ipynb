{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "00453ef4",
            "metadata": {},
            "source": [
                "# Phase 3: Advanced & Optimized Modeling\n",
                "\n",
                "## 1. Objective\n",
                "We aim to build a high-performance sentiment classifier using **Review Text**, **Brand**, and **Category**. \n",
                "\n",
                "### Professional Elevation Enhancements:\n",
                "1. **Parallelism**: Using `n_jobs=-1` for multi-core execution.\n",
                "2. **Dimensionality Reduction**: Using `TruncatedSVD` (Latent Semantic Analysis) to condense text features.\n",
                "3. **Fast Gradient Boosting**: Using XGBoost with `tree_method='hist'` for rapid training.\n",
                "4. **K-Fold Cross-Validation**: Ensuring the model is robust across data subsets.\n",
                "5. **SMOTE Oversampling**: Generating synthetic data to fix severe class imbalance.\n",
                "6. **Deep Error Analysis**: Inspecting specific misclassifications and bias."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e102ed5",
            "metadata": {},
            "source": [
                "## 2. Setup and Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9a9fd224",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import joblib\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.decomposition import TruncatedSVD\n",
                "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
                "\n",
                "import xgboost as xgb\n",
                "from imblearn.pipeline import Pipeline as ImbPipeline\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "tqdm.pandas()\n",
                "\n",
                "# Load cleaned data\n",
                "data_path = os.path.join('..', 'data', 'interim', 'cleaned_amazon.csv')\n",
                "df = pd.read_csv(data_path)\n",
                "\n",
                "# Target Binning (Neg: 0, Neu: 1, Pos: 2)\n",
                "df['sentiment'] = df['reviews.rating'].map({1: 0, 2: 0, 3: 1, 4: 2, 5: 2})\n",
                "\n",
                "# Clean metadata and text\n",
                "df = df.dropna(subset=['cleaned_text', 'brand', 'categories'])\n",
                "df = df[df['cleaned_text'].str.strip().astype(bool)]\n",
                "\n",
                "print(f\"Final Dataset Shape: {df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4f182f46",
            "metadata": {},
            "source": [
                "## 3. Data Splitting (Stratified)\n",
                "We maintain an 80/20 split, ensuring sentiment ratios are preserved."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "32f52938",
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df[['cleaned_text', 'brand', 'categories']]\n",
                "y = df['sentiment']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "696d4d23",
            "metadata": {},
            "source": [
                "## 4. Feature Engineering: Pipelines\n",
                "We define our preprocessors for text (TF-IDF + SVD) and categories (OneHot)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0f68668",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Text sub-pipeline\n",
                "text_transformer = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english', min_df=5)),\n",
                "    ('svd', TruncatedSVD(n_components=100, random_state=42)),\n",
                "    ('scaler', StandardScaler()) # Added for LogReg stability\n",
                "])\n",
                "\n",
                "# Main preprocessor\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('text', text_transformer, 'cleaned_text'),\n",
                "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['brand', 'categories'])\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Preprocessor for Naive Bayes (No SVD/Scaler)\n",
                "nb_preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('text', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english', min_df=5), 'cleaned_text'),\n",
                "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['brand', 'categories'])\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "24205be6",
            "metadata": {},
            "source": [
                "## 5. Model 1: Multinomial Naive Bayes (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c943a817",
            "metadata": {},
            "outputs": [],
            "source": [
                "nb_pipeline = Pipeline([('preprocessor', nb_preprocessor), ('clf', MultinomialNB())])\n",
                "nb_pipeline.fit(X_train, y_train)\n",
                "print(\"Naive Bayes trained.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3c4b5e86",
            "metadata": {},
            "source": [
                "## 6. Model 2: Logistic Regression (Weighted)\n",
                "Professional Benchmark: Using `class_weight='balanced'`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b120b87f",
            "metadata": {},
            "outputs": [],
            "source": [
                "lr_pipeline = Pipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('clf', LogisticRegression(class_weight='balanced', max_iter=2000, n_jobs=-1, random_state=42))\n",
                "])\n",
                "lr_pipeline.fit(X_train, y_train)\n",
                "print(\"Logistic Regression (Weighted) trained.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5e7f1b7d",
            "metadata": {},
            "source": [
                "## 7. Model 3: XGBoost (Optimized)\n",
                "Performance focus: `tree_method='hist'` and `n_jobs=-1`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee476ac9",
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb_pipeline = Pipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('clf', xgb.XGBClassifier(tree_method='hist', n_jobs=-1, random_state=42, eval_metric='mlogloss'))\n",
                "])\n",
                "xgb_pipeline.fit(X_train, y_train)\n",
                "print(\"XGBoost trained.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "568fb055",
            "metadata": {},
            "source": [
                "## 8. Professional Elevation: SMOTE Resampling\n",
                "Comparing weights against **Synthetic Minority Over-sampling**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f0a788e1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Note: We use ImbPipeline from imblearn to ensure SMOTE only applies to training folds\n",
                "smote_pipeline = ImbPipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('smote', SMOTE(random_state=42)),\n",
                "    ('clf', LogisticRegression(max_iter=2000, n_jobs=-1, random_state=42))\n",
                "])\n",
                "\n",
                "print(\"Training SMOTE Pipeline (this may take longer)...\")\n",
                "smote_pipeline.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "62d75dae",
            "metadata": {},
            "source": [
                "## 9. Professional Elevation: 5-Fold Cross-Validation\n",
                "Verifying that our results are not just a \"lucky split\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "62923197",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Running 5-Fold Cross-Validation on Logistic Regression...\")\n",
                "cv_results = cross_validate(lr_pipeline, X_train, y_train, cv=5, scoring='f1_macro')\n",
                "print(f\"Mean F1 (Macro): {cv_results['test_score'].mean():.4f} (+/- {cv_results['test_score'].std()*2:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8f253003",
            "metadata": {},
            "source": [
                "## 10. Deep Evaluation & Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "72632d7d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_all(pipelines):\n",
                "    results = []\n",
                "    for name, pipe in pipelines.items():\n",
                "        y_pred = pipe.predict(X_test)\n",
                "        results.append({\n",
                "            \"Model\": name,\n",
                "            \"F1 (Macro)\": f1_score(y_test, y_pred, average='macro'),\n",
                "            \"Report\": classification_report(y_test, y_pred, output_dict=True)\n",
                "        })\n",
                "    return pd.DataFrame(results)\n",
                "\n",
                "models_dict = {\n",
                "    \"Naive Bayes\": nb_pipeline,\n",
                "    \"LogReg (Weighted)\": lr_pipeline,\n",
                "    \"LogReg (SMOTE)\": smote_pipeline,\n",
                "    \"XGBoost\": xgb_pipeline\n",
                "}\n",
                "\n",
                "leaderboard = evaluate_all(models_dict)\n",
                "display(leaderboard.sort_values(\"F1 (Macro)\", ascending=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "772a420c",
            "metadata": {},
            "source": [
                "## 11. Error Discovery: Misclassification Audit\n",
                "Inspecting the cases where the model failed most significantly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ace3175a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using the best performer (assume LR for this analysis)\n",
                "y_pred_final = lr_pipeline.predict(X_test)\n",
                "test_analysis = X_test.copy()\n",
                "test_analysis['actual'] = y_test\n",
                "test_analysis['pred'] = y_pred_final\n",
                "\n",
                "# Find 'Severe' Errors: Actual Negative predicted as Positive\n",
                "severe_errors = test_analysis[(test_analysis['actual'] == 0) & (test_analysis['pred'] == 2)]\n",
                "\n",
                "print(f\"Number of Severe Errors (Neg -> Pos): {len(severe_errors)}\")\n",
                "print(\"\\n--- Sample Severe Errors ---\")\n",
                "display(severe_errors[['cleaned_text', 'brand']].head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c962d060",
            "metadata": {},
            "source": [
                "## 12. Bias Audit: Performance by Brand\n",
                "Is our model biased towards certain brands?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b5415be",
            "metadata": {},
            "outputs": [],
            "source": [
                "test_analysis['correct'] = test_analysis['actual'] == test_analysis['pred']\n",
                "brand_accuracy = test_analysis.groupby('brand')['correct'].mean().sort_values()\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "brand_accuracy.head(10).plot(kind='barh', color='salmon')\n",
                "plt.title(\"Accuracy by Brand (Bottom 10)\")\n",
                "plt.xlabel(\"Accuracy Rate\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".nlpvenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
